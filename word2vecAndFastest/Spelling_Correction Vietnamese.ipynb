{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP5PWz9SlVYyLSNZNwwIb4w"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import re\n","from collections import defaultdict\n","import math\n","import operator"],"metadata":{"id":"vGNmP0poGIEe","executionInfo":{"status":"ok","timestamp":1686554527256,"user_tz":-420,"elapsed":1197,"user":{"displayName":"0330- Lê Nguyễn Anh Nhật","userId":"07393004795663485962"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["** Xây dụng class N-gram tính xác suất và lưu trữ N-gram**"],"metadata":{"id":"14DhFlO2GTIR"}},{"cell_type":"code","source":["# Xây dựng class N-gram\n","class N_Gram:\n","    def __init__(self, n=2, trie = None ): # đưa cây trie đã được train và n-gram cụ thể \n","        self.n = n\n","        self.alpha = 1.0    # dùng cho khi nào sác xuất đầu ra là 0\n","        self.prob_ngram = {}        \n","        self.count_n = {}\n","        self.trie = trie\n","        \n","    \n","    def train(self, sentense):  # Hàm này sẽ train corpus có type là  list(String)  cụ thể là một list chứa các token liên tiếp nhau\n","\n","      for i in range(len(sentense)):\n","\n","          # Lấy các lần xuất hiện của bigram   \n","          if i+1<len(sentense):\n","          \n","              if ((sentense[i],sentense[i+1]) in self.count_n ):\n","                  self.count_n[(sentense[i],sentense[i+1])] += 1 # nó được lưu trữ theo tuần tự\n","              else:\n","                  self.count_n[(sentense[i],sentense[i+1])] = 1\n","  # Tính xác suất cho từng biagram\n","        \n","      for token in self.count_n:\n","          self.prob_ngram[token] =  self.Prob_Ngram(token)\n","            \n","            \n","    def Prob_Ngram(self, token): # đầu vào là các token của  N-gram và tính xác suất xuất hiện của nó\n","    # sữ dụng smoothing\n","    # Xác suất tính bằng só lần xuất hiện của N-gram đó chia cho số lần xuất hiện thông thường của unigram\n","        return (self.count_n[token] + self.alpha )/(self.trie.FindCount(self.trie.root,token[0]) + trie.V)\n","          \n","        # Tính độ phức tạp\n","    def Calculate_Perlexity (self, text):\n","        words = re.findall(r'\\b\\w+\\b', text.lower())\n","        perlexity = 1\n","        biagram_prob = 1\n","        for i in range(1,len(text)):\n","            if ((words[i-1],words[i]) in self.prob_ngram):\n","                biagram_prob *= self.prob_ngram[(words[i-1],words[i])]\n","            else:\n","                if words[i-1] in self.count_n:\n","                    biagram_prob =biagram_prob * (1/(self.count_n[words[i-1]] + self.V  ))\n","                else:\n","                    biagram_prob *=0.000000001\n","                    \n","        perlexity  *= 1/biagram_prob\n","        perplexity = math.pow(perplexity, 1.0 / len(words))\n","        \n","        return perplexity\n","        "],"metadata":{"id":"WFPhv0BrGdLt","executionInfo":{"status":"ok","timestamp":1686554530872,"user_tz":-420,"elapsed":11,"user":{"displayName":"0330- Lê Nguyễn Anh Nhật","userId":"07393004795663485962"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["Xây dựng cấu trúc dữ liệu cây Trie đẻ lưu trữ và tìm kiếm *unigram* "],"metadata":{"id":"O-knhIy_Gn_d"}},{"cell_type":"code","source":["class TrieNode:\n","  def __init__(self):\n","      self.children = {}\n","      self.end_word = False\n","      self.value = None\n","      self.count = 0\n","      \n","\n","class Trie:\n","  def __init__(self):\n","      self.root = TrieNode()\n","      self.V = 0\n","  # Hàm thêm token vào\n","  def Insert(self, x, key):      \n","    for i in range(0, len(key)):\n","        if key[i] not in x.children:\n","            x.children[key[i]] = TrieNode()\n","            x = x.children[key[i]]\n","        else:\n","\n","            x = x.children[key[i]]\n","    if x.end_word == False:\n","      self.V +=1\n","    \n","    x.end_word = True\n","    x.value = key\n","    x.count +=1\n","  # Hàm tìm kiếm giá trị đếm của token\n","  def FindCount(self,x, key):\n","    for i in range(0, len(key)):\n","        if key[i] not in x.children:\n","            return False\n","        else:\n","            x = x.children[key[i]]\n","    if x.end_word:\n","        return x.count\n","    else:\n","        return False\n","  \n","  # Hàm tìm kiếm token có tồn tại hay không\n","  def FindWord(self,x, key):\n","    \n","    for i in range(0, len(key)):\n","        if key[i] not in x.children:\n","            return False\n","        else:\n","            x = x.children[key[i]]\n","    if x.end_word:\n","        return x.value\n","    else:\n","        return False\n","\n","  # Hàm xóa token nếu token đó không phù hợp\n","  def Delete(self,x, key):\n","    if len(key) == 0:\n","        if x.end_word == True:\n","            x.end_word = False\n","            x.value = None\n","        for i in range(len(x.children)):\n","            if key[i] in x.children:\n","                return x # Nếu trong từ này còn có các chuỗi khác thì trả về x\n","        return None # còn không thì xóa uôn nhánh key\n","    x.children[key[0]] = self.Delete(x.children[key[0]], key[1:])\n","    return x\n","\n","# Phương thức in ra màn hình cho biết các token được viết vào thành công\n","  def __str__(self):\n","    return str(self._get_words(self.root))\n","\n","  def _get_words(self, x):\n","    words = []\n","    if x.end_word:\n","        words.append(x.value)\n","    for c in x.children:\n","        words.extend(self._get_words(x.children[c]))\n","    return words\n","\n","\n","# Phương thức tìm kiếm word error và đưa ra các từ đại diện, khi dùng hàm này thì từ đó chắc chăn phải lỗi\n","  def FindSpelling(self,x, key):\n","    candidates = set()\n","    for i in range(0,len(key)):\n","      if key[i] not in x.children: # xảy ra ba trường hợp là lỗ thiếu chử, lỗ thêm chữ và lỗi chữ bị thay đổi\n","        deletion =  key[:i]+ key[i+1:]\n","        candidates.add(deletion)\n","\n","        for c in x.children:\n","          subtution = key[:i] + c + key[i+1:]\n","          candidates.add(subtution)\n","\n","        for c in x.children:\n","          insertion = key[:i] + c + key[i:]\n","          candidates.add(insertion)\n","        break\n","      else:\n","        \n","        x =  x.children[key[i]]\n","   \n","\n","    accurate_candidates = set()\n","    \n","    for candidate in candidates:\n","        if self.FindWord(self.root, candidate):\n","            accurate_candidates.add(candidate)\n","    return accurate_candidates # trả về set\n","  \n","\n","    "],"metadata":{"id":"-vk4fvngG5d-","executionInfo":{"status":"ok","timestamp":1686554534531,"user_tz":-420,"elapsed":7,"user":{"displayName":"0330- Lê Nguyễn Anh Nhật","userId":"07393004795663485962"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["Dùng Edit Distance để tính khoảng cách giữa hai từ với nhau"],"metadata":{"id":"HmRXsHhXHFOg"}},{"cell_type":"code","source":["\n","def edit_distance(s1, s2):\n","    dp = [[0 for j in range(len(s2) + 1)] for i in range(len(s1) + 1)]\n","    for i in range(1, len(s2) + 1):\n","        dp[0][i] = i\n","\n","    for i in range(1, len(s1) + 1):\n","        dp[i][0] = i\n","\n","    for i in range(1, len(s1) + 1):\n","        for j in range(1, len(s2) + 1):\n","            dp[i][j] = min(min(dp[i - 1][j], dp[i][j - 1]) + 1, dp[i - 1][j - 1] + (1 if s1[i - 1] != s2[j - 1] else 0))\n","\n","    return dp[len(s1)][len(s2)]\n","\n","\n","\n","# Hàm chỉnh sữa thêm words trả về set các từ đã được chỉnh sưa từ từ bị sai lỗi chính tả \n","\n","def edits1(word):\n","    \"\"\"Tất cả các ký tự cơ bản\"\"\"\n","    \"\"\" Ý tưởng dùng xóa, thêm, chỉnh, đổi vị trí để tạo ra từ mới cho việc tìm kiếm chuyển đổi của word \"\"\"\n","    \n","    letters = [\"a\",\"â\",\"ă\",\"b\",\"c\",\"d\",\"đ\",\"e\",\"ê\",\"g\",\"h\",\"i\",\"k\",\"l\",\"m\",\"n\",\"o\",\"ô\",\"ơ\",\"p\",\"q\",\"r\",\"s\",\"t\",\n","               \"u\",\"ư\",\"v\",\"x\",\"y\"]\n","    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n","\n","\n","    deletes = [L + R[1:] for L, R in splits if R]\n","\n","    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n","\n","    replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n","\n","    inserts = [L + c + R for L, R in splits for c in letters]\n","\n","    return set(deletes + transposes + replaces + inserts)\n"],"metadata":{"id":"MhKQ8drWHMDY","executionInfo":{"status":"ok","timestamp":1686554539297,"user_tz":-420,"elapsed":743,"user":{"displayName":"0330- Lê Nguyễn Anh Nhật","userId":"07393004795663485962"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["Xây dựng class Spelling corection có các phương thức tìm lỗi chính tả và gợi ý từ phù họp"],"metadata":{"id":"bzRgdkXiHvAl"}},{"cell_type":"code","source":["\n","\n","class SpellingCorrection(N_Gram):\n","    def __init__ (self, n_gram =2, trie = None):\n","      super().__init__(n_gram, trie)\n","      \n","    \n","    def ZeroProb(self, twotoken):\n","      return (self.alpha )/(self.trie.FindCount(self.trie.root,token[0]) + trie.V)\n","\n","    def SuggestCandidates(self, sentences): # sentenses is type String, type ouput is list[set], list[int], list[string]\n","      token = sentences.split()\n","      candidates =  []\n","      indexError = []\n","      for i in range(len(token)):\n","        if self.trie.FindWord(self.trie.root, token[i]):\n","          pass\n","        else:\n","          candidates.append(self.trie.FindSpelling(self.trie.root, token[i]))\n","          indexError.append(i)\n","\n","          print(\" Chữ \"+ token[i]  + \" bị sai lỗi chính tả, nó nằm ở vị trí thứ \"+str(i+1)+ \"\\n\")\n","          print(token)\n","      return candidates, indexError, token\n","\n","\n"," \n","\n","    def ProbSentences(self, token, index): # token is type  list[string], return prob\n","      if index == 0:\n","          if (token[index], token[index + 1]) in self.prob_ngram:\n","            return math.log10( 1/self.prob_ngram[ (token[index], token[index + 1])] )\n","          else:\n","            return math.log10(1/self.ZeroProb((token[index], token[index + 1])))\n","\n","      else:\n","          if index + 1 == len(token):\n","              if (token[index-1], token[index]) in self.prob_ngram:\n","                return math.log10( 1/self.prob_ngram[ (token[index-1], token[index]) ]) \n","              else:\n","                return math.log10(1/self.ZeroProb((token[index-1], token[index])))\n","          else:\n","              if (token[index-1], token[index]) in self.prob_ngram:\n","                a=self.prob_ngram[(token[index-1],token[index])]\n","              else:\n","                a= self.ZeroProb((token[index-1], token[index]))\n","              if (token[index], token[index + 1]) in self.prob_ngram:\n","                b= self.prob_ngram[(token[index],token[index + 1])]\n","              else:\n","                b= self.ZeroProb((token[index], token[index + 1]))\n","              print(a)\n","              print(b)\n","              return math.log10( 1/(a*b))\n","      raise KeyError(\"Probabilities not found for given tokens\")\n","\n","      \n","    \n","    def SuggestProbToken(self, sentences):\n","      candidates, indexError, token  =  self.SuggestCandidates(sentences)\n","      # Kiểm tra xem giá trị xác suất của trước và sau của từ này \n","      prob_candidates = {}\n","      for index in range(len(candidates)):\n","        for realtoken in candidates[index]:\n","          token[indexError[index]] =  realtoken\n","          print(token)\n","          prob_candidates[realtoken]  = self.ProbSentences(token, indexError[index])\n","      return prob_candidates, indexError, token\n","\n","    # DE XUAT TU DUNG\n","    def SuggestSentences(self, sentences):\n","      prob_candidates, indexError, token =  self.SuggestProbToken(sentences.lower())\n","      print(prob_candidates)\n","      for i in range(len(indexError)):\n","        try:\n","          min_value_key = min(prob_candidates.items(), key=operator.itemgetter(1))[0]\n","        except KeyError:\n","          print(\"Từ điển trống. Không tìm thấy giá trị nhỏ nhất.\")\n","          break\n","        token[indexError[i]]  =  min_value_key\n","      \n","      realSentences =  \" \".join(token).capitalize()\n","      return realSentences\n"],"metadata":{"id":"oZon57r0H48f","executionInfo":{"status":"ok","timestamp":1686555536208,"user_tz":-420,"elapsed":358,"user":{"displayName":"0330- Lê Nguyễn Anh Nhật","userId":"07393004795663485962"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["Đọc dữ liệu và train"],"metadata":{"id":"3aJUfGWFmIrR"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uZ58k2K5k_jX","executionInfo":{"status":"ok","timestamp":1686554558487,"user_tz":-420,"elapsed":5157,"user":{"displayName":"0330- Lê Nguyễn Anh Nhật","userId":"07393004795663485962"}},"outputId":"26aab9f3-3a4a-4ffe-c04c-a43d2cf0adc1"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["file_path = '/content/drive/MyDrive/RealWord/data_news.txt'\n","with open(file_path, 'r', encoding = \"utf-8\") as f:\n","    file_contents = f.read().lower()"],"metadata":{"id":"byueV2VjlhQD","executionInfo":{"status":"ok","timestamp":1686554561285,"user_tz":-420,"elapsed":370,"user":{"displayName":"0330- Lê Nguyễn Anh Nhật","userId":"07393004795663485962"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["corpus = file_contents.split()"],"metadata":{"id":"wRdAZvyQL2nF","executionInfo":{"status":"ok","timestamp":1686554563239,"user_tz":-420,"elapsed":484,"user":{"displayName":"0330- Lê Nguyễn Anh Nhật","userId":"07393004795663485962"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["trie = Trie()\n","for token in corpus:\n","  trie.Insert(trie.root,token)"],"metadata":{"id":"1wI0WgQoMPIu","executionInfo":{"status":"ok","timestamp":1686555543086,"user_tz":-420,"elapsed":2225,"user":{"displayName":"0330- Lê Nguyễn Anh Nhật","userId":"07393004795663485962"}}},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":["# train cho N-gram"],"metadata":{"id":"GJqYy4S2Mw24"}},{"cell_type":"code","source":["spellingCheck  = SpellingCorrection(2,trie)\n","spellingCheck.train(corpus)"],"metadata":{"id":"k5lsDLJXM0oB","executionInfo":{"status":"ok","timestamp":1686555546932,"user_tz":-420,"elapsed":2247,"user":{"displayName":"0330- Lê Nguyễn Anh Nhật","userId":"07393004795663485962"}}},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["spellingCheck.prob_ngram[(\"hà\",\"thành\")]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T2ri3Ob2OBYb","executionInfo":{"status":"ok","timestamp":1686554576091,"user_tz":-420,"elapsed":372,"user":{"displayName":"0330- Lê Nguyễn Anh Nhật","userId":"07393004795663485962"}},"outputId":"9b21e72a-fa7e-4ed0-9b6f-a3982bee09a6"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.002949215940152496"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["print(spellingCheck.SuggestSentences(\"Tôi biet cô ấy\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4COakC8nXjg3","executionInfo":{"status":"ok","timestamp":1686555550086,"user_tz":-420,"elapsed":344,"user":{"displayName":"0330- Lê Nguyễn Anh Nhật","userId":"07393004795663485962"}},"outputId":"e33356b4-07f5-4111-9c2f-d9271dcb704d"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":[" Chữ biet bị sai lỗi chính tả, nó nằm ở vị trí thứ 2\n","\n","['tôi', 'biet', 'cô', 'ấy']\n","['tôi', 'birt', 'cô', 'ấy']\n","7.875876191226274e-05\n","7.875876191226274e-05\n","['tôi', 'biệt', 'cô', 'ấy']\n","7.875876191226274e-05\n","7.875876191226274e-05\n","['tôi', 'biết', 'cô', 'ấy']\n","0.0010429859196900843\n","0.00047564041584562073\n","{'birt': 8.207402239179029, 'biệt': 8.207402239179029, 'biết': 6.304442804372275}\n","Tôi biết cô ấy\n"]}]},{"cell_type":"code","source":["spellingCheck.prob_ngram[('yêu', 'cô')]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3P6rbpcbbKP","executionInfo":{"status":"ok","timestamp":1686554581685,"user_tz":-420,"elapsed":338,"user":{"displayName":"0330- Lê Nguyễn Anh Nhật","userId":"07393004795663485962"}},"outputId":"19ffdd14-1549-4ea7-a398-2c6a299ba2a5"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.00014847809948032666"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["if (\"tôi\",\"yêu\") in spellingCheck.prob_ngram:\n","  print(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FdzB3zRunPr4","executionInfo":{"status":"ok","timestamp":1686554584058,"user_tz":-420,"elapsed":364,"user":{"displayName":"0330- Lê Nguyễn Anh Nhật","userId":"07393004795663485962"}},"outputId":"3a17574e-cc47-488f-8445-75d8a1f1ee9e"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n"]}]}]}